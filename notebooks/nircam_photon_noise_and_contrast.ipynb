{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the Pandeia engine with the NIRCam coronagraphs. Specifically, it provides examples of:\n",
    "* Scene construction and instrument configuration\n",
    "* Engine calculations (using the bundled precomputed PSF library)\n",
    "* Basic data reduction with PSF subtraction\n",
    "* Iterating over instrument configurations to optimize observations\n",
    "* Contrast calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pandeia.engine.calc_utils import build_default_calc\n",
    "from pandeia.engine.perform_calculation import perform_calculation\n",
    "\n",
    "import jwst_pancake as pancake\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Scene\n",
    "\n",
    "We'll start by defining the source and instrument properties for our desired observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mV =10.\n",
    "ref_mV = 9.\n",
    "\n",
    "target_Sp = 'a5v'\n",
    "ref_Sp = 'a3v'\n",
    "\n",
    "subarray = 'sub640'\n",
    "filter_c = 'f210m'\n",
    "mask_c = 'mask210r'\n",
    "\n",
    "ngroup = 20\n",
    "nint = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load in a NIRCam template and configure the instrument for our observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the template\n",
    "config = build_default_calc('jwst', 'nircam', 'coronagraphy')\n",
    "\n",
    "# Set the coronagraph and filter\n",
    "config['configuration']['detector']['subarray'] = subarray\n",
    "config['configuration']['detector']['ngroup'] = ngroup\n",
    "config['configuration']['instrument']['aperture'] = mask_c\n",
    "config['configuration']['instrument']['filter'] = filter_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template contains a scene with a single star. We'll set the star properties and then duplicate it to create a planetary companion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the target (the first entry in the 'scene' list)\n",
    "target = config['scene'][0]\n",
    "target['spectrum']['normalization'] = {'type': 'photsys', 'norm_fluxunit': 'abmag', 'bandpass': 'johnson,j'}\n",
    "target['spectrum']['normalization']['norm_flux'] = target_mV\n",
    "target['spectrum']['sed'] = {'sed_type': 'phoenix'}\n",
    "target['spectrum']['sed']['key'] = target_Sp\n",
    "target['id'] = 1\n",
    "\n",
    "# Copy the target star and turn it into a planet\n",
    "planetA = deepcopy(target)\n",
    "planetA['id'] = 2 #each source must have a unique ID, starting at 1\n",
    "\n",
    "# A different way to normalize source flux\n",
    "planetA['spectrum']['normalization']['bandpass'] = 'nircam,sw_imaging,f210m'\n",
    "planetA['spectrum']['normalization']['norm_flux'] = 16.5\n",
    "planetA['spectrum']['normalization']['type'] = 'jwst'\n",
    "planetA['spectrum']['sed']['sed_type'] = 'blackbody'\n",
    "planetA['spectrum']['sed']['temp'] = 900.\n",
    "del planetA['spectrum']['sed']['key'] #unnecessary now\n",
    "\n",
    "# Source offset\n",
    "planetA['position']['x_offset'] = 0.406 #arcsec\n",
    "planetA['position']['y_offset'] = -1.263\n",
    "\n",
    "# Copy that planet and turn it into a second one\n",
    "planetB = deepcopy(planetA)\n",
    "planetB['id'] = 3\n",
    "planetB['position']['x_offset'] = -0.306 #arcsec\n",
    "planetB['position']['y_offset'] = -.53\n",
    "\n",
    "# Update calculation file with the new planet\n",
    "config['scene'].extend([planetA,planetB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotate the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pancake.scene.rotate_scene(config['scene'],35.,center=[0.,0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll add in a global offset to the entire scene to capture the effect of target acquisition error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errx, erry = pancake.scene.get_ta_error()\n",
    "pancake.scene.offset_scene(config['scene'],errx,erry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the reference scene for PSF subtraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = config['strategy']['psf_subtraction_source']\n",
    "\n",
    "# We adopt a brighter but spectrally-mismatched reference\n",
    "reference['id'] = 99\n",
    "reference['spectrum'] = deepcopy(target['spectrum'])\n",
    "reference['spectrum']['normalization']['norm_flux'] = ref_mV\n",
    "reference['spectrum']['sed']['key'] = ref_Sp\n",
    "\n",
    "# And add target acquisition error\n",
    "errx_ref, erry_ref = pancake.scene.get_ta_error()\n",
    "pancake.scene.offset_scene([reference],errx_ref,erry_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll plot the two scenes we've constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121,polar=True)\n",
    "pancake.scene.plot_scene(config['scene'],'Target Scene w/ Companion',newfig=False)\n",
    "ax = plt.gca()\n",
    "ax.set_rlim(0,5.)\n",
    "plt.subplot(122,polar=True)\n",
    "pancake.scene.plot_scene([reference],'Reference Scene',newfig=False)\n",
    "ax = plt.gca()\n",
    "ax.set_rlim(0,5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Pandeia Engine\n",
    "\n",
    "Now we pass our calculation files to the pandeia engine to create the slope images (and a number of other products).\n",
    "\n",
    "The most direct way to do so is to pass the calculation file to ```pancake.engine.perform_calculation.``` However, in order to get both the target and the reference spectrum individually, the convenience function ```pancake.engine.calculate_all``` will calculate both the target and reference in a single function (and, in pandeia 1.3 and above, in a single calculation).\n",
    "\n",
    "### Wave Sampling\n",
    "\n",
    "An aside on performance and accuracy: The ```engine.options.wave_sampling``` parameter provides a hook into the wavelength sampling of the 3D (x,y,wavelength) cube. By default, Pandeia adopts some large value for the wavelength sampling (typically 150+); however, this is the primary time sink in the calculation. Setting ```engine.options.wave_sampling = 10``` while developing your simulation provides dramatic time savings while getting within ~5% of the \"true\" value. By ```engine.options.wave_sampling = 40```, one can expect agreement to within roughly 1%.\n",
    "\n",
    "### On-the-fly PSF Calculations\n",
    "\n",
    "The Pandeia engine relies on a library of precomputed PSFs that are sparsely sampled across the coronagraphic field of view. For some observing strategies or coronagraphs, this sparse sampling will often be insufficient for accurately capturing PSF variations arising from small offsets.\n",
    "\n",
    "Pandeia-Coronagraphy gives the option (```engine.options.on_the_fly_PSFs```) to circumvent the use of this precomputed library and force recomputing each PSF on the fly in WebbPSF.\n",
    "\n",
    "NIRCam is, in general, less sensitive to spatial variations, so we won't bother toggling it to True here. See the notebooks with small grid dithers or MIRI for examples of on-the-fly PSF calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pancake.engine.calculate_all(config)\n",
    "\n",
    "targ_results = results['target']\n",
    "ref_results = results['reference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the detector images (in e$^-$/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_slope = targ_results['2d']['detector']\n",
    "reference_slope = ref_results['2d']['detector']\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(target_slope)\n",
    "plt.title('Target Slope Image')\n",
    "plt.colorbar().set_label('e$^{-}$/s')\n",
    "plt.subplot(122)\n",
    "plt.imshow(reference_slope)\n",
    "plt.title('Reference Slope Image')\n",
    "plt.colorbar().set_label('e$^{-}$/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check for saturation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sat = targ_results['2d']['saturation']\n",
    "reference_sat = ref_results['2d']['saturation']\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(target_sat)\n",
    "plt.title('Target Saturation Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(reference_sat)\n",
    "plt.title('Reference Saturation Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing\n",
    "\n",
    "Subtract the registered and scaled reference PSF from the target image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-subtract the two images (and handle any NaNs)\n",
    "centered_target = target_slope - np.nanmean(target_slope)\n",
    "centered_reference = reference_slope - np.nanmean(reference_slope)\n",
    "centered_reference[np.isnan(centered_reference)] = np.nanmax(centered_reference)\n",
    "\n",
    "# Register the reference to the target and renormalize\n",
    "registered_ref = pancake.analysis.register_to_target(centered_reference,centered_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(centered_target - registered_ref)\n",
    "plt.colorbar().set_label('e$^{-}$/s')\n",
    "plt.title('After Reference-Subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Observation Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngroup_list = range(2,8)\n",
    "\n",
    "raw_images = []\n",
    "refsub_images = []\n",
    "for ngroup in ngroup_list:    \n",
    "    #Exposure parameters\n",
    "    numberofgroups = ngroup\n",
    "    numberofints = 1\n",
    "    current_config = deepcopy(config)\n",
    "    current_config['configuration']['detector']['ngroup'] = numberofgroups\n",
    "    current_config['configuration']['detector']['nint'] = numberofints\n",
    "\n",
    "    #Pandeia calculation\n",
    "    results = pancake.engine.calculate_all(current_config)\n",
    "    occ_results = results['target']\n",
    "    ref_results = results['reference']\n",
    "    occ_slope = occ_results['2d']['detector']\n",
    "    ref_slope = ref_results['2d']['detector']\n",
    "\n",
    "    #PSF subtraction assuming photon noise, the normalization is done properly \n",
    "    centered_occ = occ_slope - np.nanmean(occ_slope)\n",
    "    centered_ref = ref_slope - np.nanmean(ref_slope)\n",
    "    reg_ref = pancake.analysis.register_to_target(centered_ref,centered_occ,rescale_reference=True)\n",
    "    ref_sub = centered_occ - reg_ref\n",
    "    \n",
    "    raw_images.append(centered_occ)\n",
    "    refsub_images.append(ref_sub)\n",
    "\n",
    "    # Uncomment to provide an indication of how quickly the calculation is proceeding\n",
    "    # print(\"Finished Iteration {} of {}\".format(len(raw_images), len(ngroup_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw, reduced in zip(raw_images,refsub_images):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(raw)\n",
    "    plt.title('Raw Data')\n",
    "    plt.colorbar().set_label('e$^{-}$/s')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(reduced)\n",
    "    plt.title('Reduced Data')\n",
    "    plt.colorbar().set_label('e$^{-}$/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Calculation File\n",
    "\n",
    "Save out your scene and instrument parameters for quick loading with a future call to ```engine.load_calculation```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pancake.engine.save_calculation(target,'mygreatcalculation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Pandeia Images\n",
    "\n",
    "```pancake.engine.save_to_fits``` is provided as a convenience function for quickly saving out arrays or cubes to a FITS file. This doesn't preserve any header values. See http://docs.astropy.org/en/stable/io/fits/ for a more complete treatment of reading and writings FITS files in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out 2d slop images\n",
    "pancake.engine.save_to_fits(targ_results['2d']['detector'],'target_slope.fits')\n",
    "pancake.engine.save_to_fits(ref_results['2d']['detector'],'reference_slope.fits')\n",
    "\n",
    "# Save out cube\n",
    "pancake.engine.save_to_fits(raw_images,'raw_cube.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limiting Contrast Calculation\n",
    "\n",
    "\n",
    "This is where we calculate the contrast as a function of exposure time. Note that in this example the limiting contrast is driven by:\n",
    "\n",
    "1. detector noise, in the Pandeia model\n",
    "2. photon noise on the speckles\n",
    "3. TA error between target and reference. \n",
    "\n",
    "There is no error due to wavefront thermal drifts or dynamical vibrations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the occulted source, we'll copy the target calculation from before and pop the planet out of the scene list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occulted = deepcopy(config)\n",
    "occulted['scene'].pop(-1)\n",
    "occulted['scene'].pop(-1)\n",
    "\n",
    "#and plot\n",
    "pancake.scene.plot_scene(occulted['scene'],'Occulted Star')\n",
    "ax = plt.gca()\n",
    "ax.set_rlim(0,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unocculted source for the contrast normalization is just the target source moved from behind the coronagraphic mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the occulted calculation file\n",
    "unocculted = deepcopy(occulted)\n",
    "#apply an offset\n",
    "unocculted['scene'][0]['position']['x_offset'] = 0.8 # arcsec\n",
    "unocculted['scene'][0]['position']['y_offset'] = 0.8 # arcsec\n",
    "\n",
    "unocculted['calculation']['effects']['saturation'] = False # Disable saturation\n",
    "\n",
    "#and plot\n",
    "pancake.scene.plot_scene(unocculted['scene'],'Unocculted Star')\n",
    "ax = plt.gca()\n",
    "ax.set_rlim(0,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We'll use the same reference as in the previous calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def quick_contrast(occulted_image,unocculted_image,n_annuli=20):\n",
    "    '''\n",
    "    A quick and dirty contrast calculation just for demonstration\n",
    "    purposes.\n",
    "    '''\n",
    "    # Convolve the unocculted image with an aperture and pick out the max \n",
    "    # as the normalization constant\n",
    "    kernel = np.array([[0,0,1,0,0], #simple aperture\n",
    "                   [0,1,1,1,0],\n",
    "                   [1,1,1,1,1],\n",
    "                   [0,1,1,1,0],\n",
    "                   [0,0,1,0,0]]).astype(float)\n",
    "    unocc_aperture = fftconvolve(unocculted_image,kernel,mode='valid')\n",
    "    norm = np.max(unocc_aperture)\n",
    "\n",
    "    # Convolve reference-subtract and raw frames with the aperture as well\n",
    "    occ_aperture = fftconvolve(occulted_image,kernel,mode='valid')\n",
    "\n",
    "    # Compute radial distance from center (in pixels)\n",
    "    indices = np.indices(unocc_aperture.shape)\n",
    "    center = np.array(unocc_aperture.shape) / 2.\n",
    "    radial = np.sqrt( (indices[0] - center[0])**2 + (indices[1] - center[1])**2 )\n",
    "    # Compute 20 annuli (uniform in radius)\n",
    "    radial_bins = np.linspace(0,np.max(radial),num=n_annuli)\n",
    "    annuli_inds = np.digitize(radial,radial_bins)\n",
    "\n",
    "    # Take the variance of raw and reference-subtracted images in each annulus and normalize by unocculted max\n",
    "    contrast = np.array([np.std(occ_aperture[annuli_inds == a]) for a in np.unique(annuli_inds)]) / norm    \n",
    "    return radial_bins, contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll iterate over exposure parameters and calculate the raw and reference-subtracted contrast at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_annuli = 30\n",
    "ngroup_list = range(2,11)\n",
    "\n",
    "raw_contrast_list = []\n",
    "refsub_contrast_list = []\n",
    "for ngroup in ngroup_list:\n",
    "    # Exposure parameters\n",
    "    numberofgroups = ngroup\n",
    "    numberofints = 1\n",
    "    occulted = deepcopy(config)\n",
    "    occulted['configuration']['detector']['ngroup'] = numberofgroups\n",
    "    occulted['configuration']['detector']['nint'] = numberofints\n",
    "    unocculted = deepcopy(config)\n",
    "    unocculted['configuration']['detector']['ngroup'] = 200\n",
    "    unocculted['configuration']['detector']['nint'] = 10\n",
    "\n",
    "    # Pandeia calculation\n",
    "    occulted_results = pancake.engine.calculate_all(occulted)\n",
    "    occ_results = occulted_results['target']\n",
    "    ref_results = occulted_results['reference']\n",
    "    unocc_results = pancake.engine.calculate_contrast(unocculted, 0.8, 0.8)\n",
    "    occ_slope = occ_results['2d']['detector']\n",
    "    unocc_slope = unocc_results['2d']['detector']\n",
    "    ref_slope = ref_results['2d']['detector']\n",
    "\n",
    "    # PSF subtraction assuming photon noise, the normalization is done properly \n",
    "    centered_occ = occ_slope - np.nanmean(occ_slope)\n",
    "    centered_ref = ref_slope - np.nanmean(ref_slope)\n",
    "    reg_ref = pancake.analysis.register_to_target(centered_ref,centered_occ)\n",
    "    ref_sub = centered_occ - reg_ref\n",
    "\n",
    "    radial_bins, raw_contrast = quick_contrast(occ_slope,unocc_slope,n_annuli=n_annuli)\n",
    "    radial_bins, refsub_contrast = quick_contrast(ref_sub,unocc_slope,n_annuli=n_annuli)\n",
    "\n",
    "    raw_contrast_list.append(raw_contrast)\n",
    "    refsub_contrast_list.append(refsub_contrast)\n",
    "    \n",
    "    # Uncomment to get feedback as the calculations run\n",
    "    # print(\"Finished iteration {} of {}\".format(len(raw_contrast_list), len(ngroup_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_scale = 0.032 # see https://jwst-docs.stsci.edu/display/JTI/NIRCam+Imaging\n",
    "mask_radii = 0.4 # see https://jwst-docs.stsci.edu/display/JTI/NIRCam+Coronagraphic+Imaging\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i,contrast in enumerate(raw_contrast_list):\n",
    "    plt.semilogy(radial_bins * pix_scale,contrast,label='Nints=1, Ngroups={}'.format(ngroup_list[i]))\n",
    "    plt.fill_between([0,mask_radii],1e-6,20,alpha=0.2,lw=0,color=[0.5,0.5,0.5])\n",
    "    plt.xlabel('Radial Separation (arcsec)')\n",
    "    plt.ylabel('Contrast')\n",
    "    plt.xlim(0,2.1)\n",
    "    plt.ylim(1e-6,1e-2)\n",
    "    plt.title('Raw Target, {} V={}, Reference {}, V={}'.format(target_Sp,target_mV,ref_Sp,ref_mV),fontsize=15)\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "plt.figure(figsize=(10,5))\n",
    "for i,contrast in enumerate(refsub_contrast_list):\n",
    "    plt.semilogy(radial_bins * pix_scale,contrast,label='Nints=1, Ngroups={}'.format(ngroup_list[i]))\n",
    "    plt.fill_between([0,mask_radii],1e-6,20,alpha=0.2,lw=0,color=[0.5,0.5,0.5])\n",
    "    plt.xlabel('Radial Separation (arcsec)')\n",
    "    plt.ylabel('Contrast')\n",
    "    plt.xlim(0,2.1)\n",
    "    plt.ylim(1e-6,1e-2)\n",
    "    plt.title('Reduced Target, {} V={}, Reference {}, V={}'.format(target_Sp,target_mV,ref_Sp,ref_mV),fontsize=15)\n",
    "    plt.legend(loc='upper right')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_pancake]",
   "language": "python",
   "name": "conda-env-test_pancake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
